\begin{abstract}
In this paper we present a method to extract models from reference animations that can reproduce movement from user input. Although much work has been to done to create realistic full body character animation there is a lack of methods for performing the supplementary task of accurate modeling between user input and future trajectory. This is important for systems that use trajectory prediction as weak control signals to guide animation synthesis, but especially for computer games where the character position is typically mapped directly to the estimated trajectory with animations overlaid as a secondary effect that is not allowed to diverge. When prediction and animations diverge visual artifacts appear and current practice requires a tedious manual alignment process to avoid this. Our method provides an automated alternative to current practice.

Input control is ill-defined as the user may not be able to faithfully reconstruct the full movement details using a gamepad. Hence, we regularize the task by introducing control genomes to represent reduced user control signals, thereby deferring complexity to our models. We further introduce movement models using a modular approach where primitives are combined and we demonstrate a model for plane locomotion in games. Finally the modeling task is further addressed by animation alignment and trajectory estimation where unwanted details are filtered.
\end{abstract}
