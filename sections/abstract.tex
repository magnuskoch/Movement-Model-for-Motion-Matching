\begin{abstract}
In this paper we present a method to extract models from reference animations that can reproduce movement from user input. Although much work has been to done to create realistic full body character animation there is a lack of methods for performing the supplementary task of accurate modeling between user input and future trajectory. This is important for systems that use weak control signals to guide animation synthesis, but especially for computer games where the character position is typically mapped directly to the estimated trajectory with animations overlaid as a secondary effect that is not allowed to diverge. When there is a discrepancy visual artifacts appear and a tedious manual alignment process is required to avoid this.

Input control is ill-defined as we could simply assume that the user is able to faithfully reconstruct the full movement details using a gamepad. As this is usually not the case we regularize the task by introducing control genomes to represent reduced user control signals, thereby deferring complexity to our models. We further introduce movement models using a modular approach where primitives are combined and we demonstrate a model for plane locomotion in games. Finally the modeling task is further addressed by animation alignment and trajectory estimation where unwanted details are filtered.
\end{abstract}
