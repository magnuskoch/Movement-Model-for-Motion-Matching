\section{Introduction}
Realistic and responsive character animation is important for establishing immersion in computer games. The complexity of human movement makes it difficult to construct such an experience by hand. Instead we record reference data using motion capture and construct animation synthesizers that either stitches clips together, samples inferred statistical models, or learns control policies for a physical model and mimics the animations. Recent advances 
%in both industry and research communities 
show a strong tendency towards complex closed systems guided by weak control signals. Notably \citep{holden.ea20} and \citep{Bergamin19} uses a spring-damper system due to \citep{kermse.04} for a motion matching system, while \citep{startke20} generate control trajectories by upsampling an unspecified smooth user input using a neural network. In \citep{zhang18} an interpolation between current and desired direction is fed directly to a generative model and in \citep{peng17} a physical model is trained to follow randomly generated paths by allowing a 2 meter divergence. 
%\kenny{Our work use XXX? or is similar to YYY? or ?}

To our best knowledge it has not been investigated how to construct and synchronize weak control signals to animation synthesizers for full body locomotion. This is important for computer games. It is an industry standard in AAA productions to have a gameplay layer that controls changes to character position and a separate animation layer that tries to generate animations that matches the changes in positions \citep{holden18}. We suggest the term \textit{movement model} to describe the gameplay layer logic that controls character position in response to player input. In game productions the movement model is carefully tuned by designers to give a response that \textit{feels appealing}, it is used to predict future character movement and even for analyzing the validity of game levels. These industry practices poses requirements to how we construct our movement models. 

The movement model seems an ideal control signal for animation synthesizers. We have a history of movement available and can integrate the model for predictions.Hence, the movement model is both a weak signal and describes the actual movement of game characters and this introduce a challenge. If there is a disconnect between the movement model and the animation synthesizer output, we might allow the animations to diverge from the movement model and later catch up. But this severely impacts the types of game experiences that can be created as we loose exact positioning of our character and it changes the feeling of movement in response to player input which is critical for immersion \magnus{(REF)}. If we enforce synchronization between the two layers artifacts such as foot sliding and a general degradation of realism and quality kick in. It is an industry standard to carefully synchronize animations and movement models by hand at great economical cost to avoid these issues. \changed{We show how current best practice compared to our method in Figure \ref{fig:teaser}.}

%We propose that it is a valuable effort to investigate movement models and suggest a procedure to do so. It is a task that runs parallel to the more researched area of modeling full body kinematics, and has stricter requirements for simplicity as models should be extremely fast to evaluate and open for manual tweaks to get the feeling of movement just right. 
We propose to investigate movement models as a valuable mechanism for handling both weak control and actual motion description. In order to be applicable in AAA game production the models are required to be simple, as automated as possible to avoid unnecessary manual labour, extremely fast to evaluate, and open for manual artistic tweaks to change the feeling of movement if needed.

In the following pages we introduce a method for composing movement models from primitives that can be automatically fitted to reference animations using auto differentiation. We suggest a model composition for plane locomotion and show procedures to simplify and align the animations to avoid modeling complex and unnecessary details while preserving visual quality. Our modeling task is ill-posed since in the limit player input could contain complex low level control signals similar to what is found in the animations, which would greatly reduce requirements to the model as the control signal would itself represent what we are trying to model. We regularize the task by using the novel concept of \textit{control genomes} to formalize the reduction of low level control input to high level signals corresponding better to expected player behavior. Finally we present a procedure to determine movement in animations from foot contact analysis which was discovered as a side effect of our work and can be used in its own right.

