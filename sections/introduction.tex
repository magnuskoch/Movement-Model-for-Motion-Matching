\section{Introduction}
Realistic and responsive character animation is important for establishing immersion in computer games. The complexity of human movement makes it difficult to construct such an experience by hand. Instead we record reference data using motion capture and construct animation synthesizers that either stitches clips together, samples inferred statistical models, or learns control policies for a physical model and mimics the animations. Recent advances in both industry and research communities show a strong tendency towards complex closed systems guided by weak control signals. Notably \citep{holden.ea20} and \citep{Bergamin19} uses a spring-damper system due to \citep{kermse.04} for a motion matching system, while \citep{startke20} generate control trajectories by upsampling an unspecified smooth user input using a neural network. In \citep{zhang18} an interpolation between current and desired direction is fed directly to a generative model and in \citep{peng17} a physical model is trained to follow randomly generated paths by allowing a 2 meter divergence. 


To our best knowledge it has not been investigated how to construct and synchronize weak control signals for full body \kenny{locomotion} animation synthesizers. This is important for computer games. It is an industry standard to have a gameplay layer that controls changes to character position and a separate animation layer that tries to generate animations that matches the changes in positions \citep{holden18}. We suggest the term \textit{movement model} to describe the gameplay layer logic that controls character position in response to player input. In game productions the movement model is carefully tuned by designers to give a response that \textit{feels appealing}, it is used to predict future character movement and even for analyzing the validity of game levels. These industry practices poses requirements to how we construct our movement models. 

The movement model seems an ideal control signal for animation synthesizers. We have a history of movement available and can integrate the model for predictions. But a challenge is introduced. The movement model is not only a weak signal since it describes the actual movement of game characters. If there is a disconnect between the movement model and the animation synthesizer output we might allow the animations to diverge from the Movement Model and later catch up. But this severely impacts the types of game experiences that can be created as we loose exact positioning of our character and it changes the feeling of movement in response to player input which is critical for immersion \magnus{(REF)}. If we enforce synchronization between the two layers artifacts such as foot sliding and a general degradation of realism and quality kick in. It is an industry standard to carefully synchronize animations and Movement Models by hand at great economical cost to avoid these issues.

We propose that it is a valuable effort to investigate movement models and suggest a procedure to do so. It is a task that runs parallel to the more researched area of modeling full body kinematics, and has stricter requirements for simplicity as models should be extremely fast to evaluate and open for manual tweaks to get the feeling of movement just right. 

In the following pages we describe a system for composing Movement Models from primitives that can be automatically fitted to reference animations using auto differentiation. We suggest a model composition for plane locomotion and show procedures to simplify and align the animations to avoid modeling complex and unnecessary details while preserving visual quality. Our modeling task is ill-posed since in the limit player input could contain complex low level control signals similar to what is found in the animations, which would greatly reduce requirements to the model as the control signal would itself represent what we are trying to model. We regularize the task by using \textit{control genomes} to formalize the reduction of low level control input to high level signals corresponding better to expected player behavior. Finally we present a novel procedure to determine movement in animations from foot contact analysis which was discovered as a side effect of our work and can be used in its own right.









% Computer games are growing. Both in scope and ambition. Virtual worlds are becoming larger and contain increasingly complex and dynamic interactions between the characters and the environment. Multiplayer game play is most commonly the norm, and requires that the internal state of the rapidly changing game world can be reliable passed around and kept synchronized between players around the world. To manage the complexity of interaction of the full game world, individual game components are usually treated as abstract models, that should be easy to reason about, to update and keep synchronised. Then as a next step more fine grained models or simply visual fidelity is added on top. 

% While it has proven extremely difficult to synthesize dynamic animations of human characters, the challenge is only greater in the context of modern game production. A common approach is to split the animation system into a abstract movement model, which produces the overall state of the game characters, and an animation system which generates animations that realistically and closely follow the path of the movement model. Introduced in 2015 Motion Matching has been adopted by many studios \kenny{as evidenced by games such ass XX, YY, ZZ}. At its core, the system stitches animations streams together by continually transitioning between frames in a large database of animation clips. The transitions are determined by finding the best matches to an external requirement which is naturally provided by the movement model. Motion matching excels when the animation database has a substantial coverage allowing the system to generate a full range of animations that are still close to the ground truth \kenny{Can we add some cites for this claim? Or we can rephrase it as: "In our experience Motion Matching excels...."}. 

% Conceptually the movement model provides a control signal into the motion database. To keep synthesized animation realistic and fluent, it is critical that this control signal is reproducible in the database. In practice this is often not the case, and the issue is addressed by manually tweaking all exposed parameters in the pipeline. Most importantly weighted heuristics are added to the motion matching system, animation trajectories are manually edited and the movement model is set to reproduce the main movement modes present in the animations. To our best knowledge the process of tweaking poses is the biggest challenge to the practical use of motion matching.

% In this paper we formulate the synchronization of the motion matching system, an animation database and movement model as an ill posed optimization procedure. We suggest a number of regularization steps, arriving at a solution that enables us to use unstructured animations for motion matching under movement model control while preserving fidelity in the database. The regularization procedure has two steps, where we first identify main modes in the animation database, and then distribute a sparse user control along all animation in the database. Manual edits to the animations is replaced by a warping system, allowing us to optimize against a wider range of valid input animations. Finally an optimization procedure is applied to the partially constrained movement model and animations to arrive at a configuration of the entire system.

% Our contribution is a conceptual formulation of the movement model, the regularization steps required to run the optimization procedure and the [something] required to make optimization work nicely.
